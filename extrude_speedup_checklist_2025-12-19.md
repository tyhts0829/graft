# extrude 高速化チェックリスト（2025-12-19）

目的: `src/grafix/core/effects/extrude.py` の実行を高速化し、頂点数が多いケースでの待ち時間とメモリ/GC 負荷を下げる。

前提:

- 仕様は維持（元ライン群 + 押し出し後ライン群 + 各頂点の接続エッジ）。
- `delta=(0,0,0), scale=1, subdivisions=0` は no-op で入力を返す（現仕様）。
- 互換ラッパー/シムは作らない（破壊的変更 OK だが、ここでは API を増やさない）。
- まだコード変更しない（このファイルは作業計画/判断材料のみ）。

## 0) 先に決める（あなたの確認が必要）

- [x] 目標: 速度優先（コードの短さより優先）
- [x] 追加依存なしで進める（NumPy + 既存 numba のみ）
- [x] Numba を使う場合: `dash` と同様の 2 パス（count→fill）方針を採用してよい（コード量増 OK）
- [x] ベンチ対象（最優先）: B（多数の短いポリライン）
  - [ ] A: 1 本の巨大ポリライン（例: 100k 点）
  - [x] B: 多数の短いポリライン（例: 10k 本 × 20 点）
  - [ ] C: subdivisions を高くしたケース（例: subdivisions=8）

## 1) 現状のボトルネック仮説（現コードを読んだ上で）

`extrude` は「接続エッジ」が頂点数ぶん生成されるため、実装次第で極端に遅くなりやすい。

- [ ] **Python ループ + 小配列の大量生成**
  - 現状は各頂点ごとに `seg = np.asarray([p, q])` を生成して `list.append` しているため、配列確保が N 回発生する。
- [ ] **`out_lines`（小配列リスト）→ `np.concatenate`**
  - 小さい配列を大量に `concatenate` すると、メモリコピー/オーバーヘッドが大きくなる。
- [ ] **dtype 変換（float64 経由）**
  - 各ラインで `float64` に変換してスケールしている（精度は良いが、速度・メモリでは不利）。
- [ ] **subdivide の反復確保**
  - `subdivisions` 回ぶん、サイズが増え続ける配列を毎回確保している（ここは上限 8 なので、支配的かは入力次第）。

## 2) 高速化アイデア（仕様不変）

### 2.1 まず効く（推奨 / 低リスク）

- [ ] **2 パス化（count→fill）で 1 回だけ確保する**
  - 各ポリラインについて「出力ポリライン数」と「出力頂点数」を先に数え、`out_coords/out_offsets` を 1 度だけ確保して埋める。
  - `dash` の実装パターンに近く、repo 内で前例がある。
- [ ] **接続エッジ生成をベクトル化**
  - `mask = ~np.allclose(line, extruded_line, atol=...)` を頂点単位で作り、
    `edges_coords[0::2] = line[mask]` / `edges_coords[1::2] = extruded_line[mask]` の形で一括生成する。
  - 「頂点ごとの seg 配列」を消せるので、ここが最大の効果点になりやすい。
- [ ] **`center_mode="auto"` の式変形で余計な配列を減らす**
  - `extruded_line = (line - centroid(line))*scale + centroid(line) + delta`
  - これにより `extruded_base` や `centroid(extruded_base)` を作らずに済む（`delta` は後で足すだけ）。
- [ ] **`scale==1` の高速経路**
  - `extruded_line = line + delta`（`center_mode` を無視できる）に落とせる。
  - `np.mean` も不要になりやすい。

### 2.2 効く可能性がある（中リスク / 入力依存）

- [ ] **subdivide の高速化**
  - 2 パスを導入するなら subdivide も「最終頂点数を先に計算」して、確保回数を減らす。
  - ただし実装が少し複雑になるので、実測で支配的なら対応する。
- [ ] **`np.linalg.norm` 回避（平方ノルム比較）**
  - `norm > MAX_DISTANCE` 判定は `norm_sq > MAX_DISTANCE**2` にできる（微小だがコスト減）。

### 2.3 さらに攻める（高リスク / コード量増）

- [ ] **Numba カーネル化**
  - `coords/offsets` を入力として、count カーネルと fill カーネルを `@njit` で用意する。
  - 目的: Python ループを完全に排除する（大量線・大量頂点で効く可能性）。
  - トレードオフ: 実装/デバッグコスト増、Numba の制約（list/可変長）に合わせた設計が必要。

## 3) ベンチ/評価の作り方（最小）

- [ ] 測定スクリプト（例: `tools/benchmarks/bench_extrude.py`）を用意し、以下を計測する
  - wall time（1 回 / 複数回）
  - peak memory（可能なら）
  - 出力頂点数・出力ポリライン数（想定どおり増えるかの sanity）
- [ ] ケースを固定して比較する（例）
  - A: 1 本 100k 点、subdivisions=0
  - B: 10k 本 × 20 点、subdivisions=0
  - C: 1 本 5k 点、subdivisions=8（最悪系）
- [ ] 成功条件を決める（例: A/B で 3x 以上、C で 2x 以上 など）

## 4) 実装の進め方（提案）

- [ ] ステップ 1: 接続エッジ生成をベクトル化（最重要）
- [ ] ステップ 2: 2 パス化（count→fill）で `concatenate` と小配列確保を消す
- [ ] ステップ 3: auto center の式変形 + `scale==1` 高速経路
- [ ] ステップ 4: まだ遅いなら subdivide/Numba を検討（実測ベース）

## 5) 事前に確認した方がよさそうな点（気づき）

- [ ] 今の仕様は「接続エッジが頂点数ぶん増える」ので、出力サイズそのものがボトルネックになり得る（速度以前にメモリ）。
  - 仕様は維持する前提だが、「接続エッジを出す/出さない」を将来オプション化する余地はある（ただし今回はやらない）。
